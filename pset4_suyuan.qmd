---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[yes](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 (name and cnet ID): Suyuan Fang - suyuanfang
    - Partner 2 (name and cnet ID): Jiaxuan nie - Jnie21 
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*\SF\*\* \*\*\JN\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set 4 **[yes](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset:1 Late coins left after submission:2
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 

## Download and explore the Provider of Services (POS) file (10 pts)
1.  
#Facility Name FAC_NAME  
#short-term PRVDR_CTGRY_SBTYP_CD  
#hospital PRVDR_CTGRY_CD  
#CMS PRVDR_NUM  
#termination PGM_TRMNTN_CD  
#termination CRTFCTN_ACTN_TYPE_CD  
#zip code ZIP_CD  
2. 
```{python}
import pandas as pd
import altair as alt

def process_hospital_data(file_path):
    df = pd.read_csv(file_path, encoding='ISO-8859-1')
    df_filtered = df[(df['PRVDR_CTGRY_CD'] == 1) & (df['PRVDR_CTGRY_SBTYP_CD'] == 1)].copy()
    year = file_path[-8:-4]  
    df_filtered.loc[:, 'Year'] = year  
    hospital_count = df_filtered.shape[0]
    print(f'Number of short-term hospitals in {year}: {hospital_count}')
    return df_filtered

pos2016 = process_hospital_data('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/pos2016.csv')
pos2017 = process_hospital_data('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/pos2017.csv')
pos2018 = process_hospital_data('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/pos2018.csv')
pos2019 = process_hospital_data('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/pos2019.csv')

data_combined = pd.concat([pos2016, pos2017, pos2018, pos2019])

output_path = '/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/combined_pos.csv'
data_combined.to_csv(output_path, index=False)

plot_data = data_combined['Year'].value_counts().reset_index()
plot_data.columns = ['Year', 'Count']
plot_data = plot_data.sort_values('Year')

chart = alt.Chart(plot_data).mark_bar(color='lightblue').encode(
    x=alt.X('Year:N', title='Year'),
    y=alt.Y('Count:Q', title='Number of Hospitals')
).properties(
    title='Number of Short-Term Hospital Observations by Year'
)
chart.display()
```
4. 
    a.
    ```{python}
    unique_hospitals_per_year = data_combined.groupby('Year')['PRVDR_NUM'].nunique().reset_index()
    unique_hospitals_per_year.columns = ['Year', 'Unique Count']

    chart_unique = alt.Chart(unique_hospitals_per_year).mark_bar(color='lightgreen').encode(
        x=alt.X('Year:N', title='Year'),
        y=alt.Y('Unique Count:Q', title='Number of Unique Hospitals')
    ).properties(
        title='Number of Unique Short-Term Hospitals by Year'
    )
    chart_unique.display()
    print("\nUnique hospital counts per year:\n", unique_hospitals_per_year)
    ```
    b.The two plots show that the total number of observations and unique hospitals per year are nearly identical, indicating that each hospital is consistently reported only once per year. This suggests the data structure is stable, with no significant duplication or variation across the years analyzed.

## Identify hospital closures in POS file (15 pts) (*)

1. 
```{python}
```
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 
1. 
    a.
    .shp (Shapefile): Holds geometric data (e.g., ZIP code boundaries).
    .shx (Index File): Provides quick access to the .shp data.
    .dbf (Database File): Contains attribute data for each shape (e.g., ZIP codes).
    .prj (Projection File): Specifies the coordinate system and projection.
    .xml (Metadata File): Describes the dataset, including sources and attributes.
    b. 
    .shp 837.5 MB
    .shx 265KB
    .dbf 6.4MB
    .prj 165B
    .xml 16KB
2. 
```{python}
import pandas as pd
import geopandas as gpd
import altair as alt

cleaned_pos2016 = pd.read_csv('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/cleaned_2016_pos.csv')

zip_shapefile_path = '/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/gz_2010_us_860_00_500k/gz_2010_us_860_00_500k.shp'
gdf = gpd.read_file(zip_shapefile_path)

print(gdf.columns)
gdf['ZIP_CODE'] = gdf['ZCTA5'].astype(str)
texas_prefixes = ['75', '76', '77', '78', '79']
gdf_texas = gdf[gdf['ZIP_CODE'].str[:2].isin(texas_prefixes)]
hospitals_per_zip = cleaned_pos2016['ZIP_CD'].value_counts().reset_index()
hospitals_per_zip.columns = ['ZIP_CODE', 'Hospital_Count']
hospitals_per_zip['ZIP_CODE'] = hospitals_per_zip['ZIP_CODE'].astype(str)
gdf_texas['ZIP_CODE'] = gdf_texas['ZIP_CODE'].astype(str)
gdf_texas = gdf_texas.merge(hospitals_per_zip, on='ZIP_CODE', how='left')

plot_data = gdf_texas[['ZIP_CODE', 'geometry', 'Hospital_Count']]
plot_data['Hospital_Count'] = plot_data['Hospital_Count'].fillna(0)

chart = alt.Chart(plot_data).mark_geoshape().encode(
    color=alt.Color('Hospital_Count:Q', scale=alt.Scale(scheme='blues'), title='Hospital Count'),
    tooltip=['ZIP_CODE', 'Hospital_Count']
).properties(
    width=800,
    height=600,
    title='Number of Hospitals by ZIP Code in Texas (2016)'
)
chart.display()
```


## Calculate zip codeâ€™s distance to the nearest hospital (20 pts) (*)

1. 


# Display the first few rows of the result
print(closures_df.head())
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
```{python}
import pandas as pd
closures_df = pd.read_csv('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/closed_Data.csv')
print(closures_df.columns)
closures_df['ZIP_CD'] = closures_df['ZIP_CD'].astype(str)
texas_prefixes = ['75', '76', '77', '78', '79']
closures_texas = closures_df[closures_df['ZIP_CD'].str[:2].isin(texas_prefixes)]
closures_count = closures_texas['ZIP_CD'].value_counts().reset_index()
closures_count.columns = ['ZIP_CD', 'Number_of_Closures']
print(closures_count)
```
2. 
```{python}
import pandas as pd
import geopandas as gpd
import altair as alt

closures_df = pd.read_csv('/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/closed_Data.csv')

print(closures_df.columns)
closures_df['ZIP_CD'] = closures_df['ZIP_CD'].astype(str)
texas_prefixes = ['75', '76', '77', '78', '79']
closures_texas = closures_df[closures_df['ZIP_CD'].str[:2].isin(texas_prefixes)]
closures_count = closures_texas['ZIP_CD'].value_counts().reset_index()
closures_count.columns = ['ZIP_CD', 'Number_of_Closures']
directly_affected_zips = closures_count.shape[0]
print(f'Number of directly affected ZIP codes in Texas: {directly_affected_zips}')
zip_shapefile_path = '/Users/suyuanfang/Desktop/Pyhton/problem-set-4-nelly-alex/gz_2010_us_860_00_500k/gz_2010_us_860_00_500k.shp'
gdf = gpd.read_file(zip_shapefile_path)
gdf['ZIP_CODE'] = gdf['ZCTA5'].astype(str)
gdf_texas = gdf[gdf['ZIP_CODE'].str[:2].isin(texas_prefixes)]
gdf_texas = gdf_texas.merge(closures_count, left_on='ZIP_CODE', right_on='ZIP_CD', how='left')
gdf_texas['Number_of_Closures'] = gdf_texas['Number_of_Closures'].fillna(0)

plot_data = gdf_texas[['ZIP_CODE', 'geometry', 'Number_of_Closures']]
chart = alt.Chart(plot_data).mark_geoshape().encode(
    color=alt.Color('Number_of_Closures:Q', scale=alt.Scale(scheme='reds'), title='Number of Closures'),
    tooltip=['ZIP_CODE', 'Number_of_Closures']
).properties(
    width=800,
    height=600,
    title='Texas ZIP Codes Directly Affected by Hospital Closures (2016-2019)'
)
chart.display()
```
3. 
```{python}
gdf_texas = gdf_texas.set_geometry('geometry')
gdf_texas = gdf_texas.to_crs(epsg=32614)  
directly_affected_gdf = gdf_texas[gdf_texas['Number_of_Closures'] > 0]


directly_affected_gdf['buffer'] = directly_affected_gdf.geometry.buffer(16093.4) 
directly_affected_gdf = directly_affected_gdf.set_geometry('buffer')
indirectly_affected_gdf = gpd.sjoin(gdf_texas, directly_affected_gdf[['buffer']], how='inner', predicate='intersects')
indirectly_affected_zips = indirectly_affected_gdf['ZIP_CODE'].nunique()
print(f'Number of indirectly affected ZIP codes in Texas: {indirectly_affected_zips}')
plot_data = indirectly_affected_gdf[['ZIP_CODE', 'geometry']]
plot_data['Affected Type'] = 'Indirectly Affected'

chart = alt.Chart(plot_data).mark_geoshape().encode(
    color=alt.Color('Affected Type:N', scale=alt.Scale(scheme='oranges'), title='Affected Type'),
    tooltip=['ZIP_CODE']
).properties(
    width=800,
    height=600,
    title='Texas ZIP Codes Indirectly Affected by Hospital Closures (2016-2019)'
)
chart.display()
```
4. 
```{python}

```
## Reflecting on the exercise (10 pts) 

1.   
To improve the identification of hospital closures, consider issues like data gaps, temporary shutdowns being mistaken for permanent closures, and name changes that might not reflect true closures. Improvements could include cross-checking with external data sources, using more comprehensive data on hospital operations, and integrating longitudinal analysis for more accurate closure verification.
2. 
